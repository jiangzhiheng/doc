一、通过域名访问服务：`k8s`中的`DNS`

1. `DNS`服务基本框架

   - 通常`Kubernetes`的`DNS`应用部署好后，会对外暴露一个服务，集群内的容器通过访问该服务的`Cluster IP+53`端口获得域名解析服务。
   - 容器想要获得域名解析服务，只需把`DNS Server`写入`/etc/resolv.conf`，`Kubelet`负责刷新`/etc/resolv.conf`配置
   - 通过`kubelet`的启动参数`--cluster-dns=<dns service ip>`，`DNS`的`IP`将在用户容器启动时传递，并写入每个容器的`/etc/resolv.conf`
   - 通过`kubelet`的启动参数`--cluster-domain=<default-local-domain>`参数支持配置集群域名后缀，默认是`cluster.local`

2. 域名解析基本原理

   - `Kubernetes DNS`加载项支持正向查找(`A Record`)，端口查找(`SRV`)，反向`IP`地址查找(`PTR`)及其它功能

   - 对于`Service`，`Kubernetes DNS`会生成三类`DNS`记录，分别是`A`记录，`SRV`记录，`CNAME`记录

     - `A`记录

       - `A`记录是用于将域或子域指向某个`IP`地址的`DNS`记录的最基本类型

       - `Kubernetes`为`normal`和`headless`服务分配不同的`A Record`。`headless`服务与`normal`服务的不同之处在于它们未分配`Cluster IP`且不执行负载均衡

       - 普通`Service`的`A Record`的映射关系是：

         ```shell
         {service name}.{service namespace}.svc.{domain} -> Cluster IP
         # domain:提供的域名后缀，kubelet通过--cluster-domain提供，默认cluster.local
         ```

       - `headless Service`的`A Record`的映射关系是

         ```
         {service name}.{service namespace}.svc.{domain} -> 后端Pod IP列表
         ```

     - `SRV`记录

       - `SRV`记录是通过描述某些服务协议和地址促进服务发现的，`SRV`记录通常定义一个符号名称和作为域名一部分的传输协议，并给定服务的优先级，权重，端口和目标

     - `CNAME`记录

       - `CNAME`记录用于将域或子域指向另一个主机名。一般用于联合服务的跨集群服务发现

3. `DNS`使用

   1. `Pod`的主机名由`pod.spec.name`指定，也可使用`pod.spec.subdomain`自定义子域名，定义后`Pod`的`FQDN`将变为`<hostname>.<subdomain>.<pod namespace>.svc.<cluster domain>`

   2. `DNS`测试

      - 创建测试`Pod`

        ```yaml
        apiVersion: v1
        kind: Pod
        metadata:
          name: busybox
          namespace: default
        spec:
          containers:
          - name: busybox
            image: busybox:1.28
            command:
            - sleep
            - "3600"
            imagePullPolicy: IfNotPresent
          restartPolicy: Always
        ```

      - 测试解析`kubernetes`默认`API Server`的`service`地址

        ```shell
        [root@master ~]# kubectl exec -it busybox -- nslookup kubernetes.default
        Server:    10.96.0.10
        Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local
        
        Name:      kubernetes.default
        Address 1: 10.96.0.1 kubernetes.default.svc.cluster.local
        ```

        ```shell
        [root@master ~]# kubectl exec -it busybox -- cat /etc/resolv.conf
        nameserver 10.96.0.10
        search default.svc.cluster.local svc.cluster.local cluster.local localdomain jzh.com
        options ndots:5
        # options ndots:5的含义是当查询的域名字符串内的点字符超过5个时，则认为是完整域名，直接解析，否则Linux系统会自动尝试用default.svc.cluster.local svc.cluster.local cluster.local 补齐域名后缀，查询过程中任意一个记录匹配便返回
        ```

4. `Kubernetes`域名解析策略：

   `Kubernetes`域名解析策略对应到`Pod`配置中的`dnsPolicy`，有四种可选策略：

   - `None`：`kubernetes 1.9+`新引入，它允许`Pod`忽略`Kubernetes`环境中的`DNS`设置，应使用`dnsConfigPod`规范中所提供的`DNS`设置。

     - 示例：

       ```yaml
       apiVersion: v1
       kind: Pod
       metadata:
         name: dns-none-policy
         namespace: default
       spec:
         containers:
         - name: test
           image: nginx:1.14-alpine
           imagePullPolicy: IfNotPresent
         dnsPolicy: "None"
         dnsConfig:
           nameservers:
           - 1.2.3.4
           searches:
           - ns1.svc.cluster.local
           - my.dns.search.suffix
           options:
           - name: ndots
             value: "2"
           - name: edns0
       ```

     - 验证

       ```shell
       [root@master testDns]# kubectl exec -it dns-none-policy -- cat /etc/resolv.conf
       nameserver 1.2.3.4
       search ns1.svc.cluster.local my.dns.search.suffix
       options ndots:2 edns0
       ```

   - `ClusterFirstWithHostNet`：对于使用`hostNetwork`运行的`Pod`，用户应该明确设置其`DNS`策略为`ClusterFirstWithHostNet`

     ```yaml
     ...
     spec:
       ...
       hostNetwork: true
       dnsPolicy: ClusterFirstWithHostNet
       ...
     
     # 对于使用主机网络的Pod，它们是可以直接访问宿主机的/etc/resolv.conf文件的，如果不添加dnsPolicy: ClusterFirstWithHostNet，Pod将会默认使用宿主机的DNS配置，这样会导致集群内容器无法通过域名访问kubernetes的服务，除非在宿主机的/etc/resolv.conf文件配置了kubernetes的DNS服务器
     ```

   - `ClusterFirst`：任何与配置的群集域后缀(例如`cluster.local`)不匹配的`DNS`查询，将转发到从宿主机上继承的上游域名服务器。集群管理员可以根据需要配置上游`DNS`服务器，默认选项。

     - `ClusterFirst`策略就是优先使用`Kubernetes`的`DNS`服务解析，失败后再使用外部级联的`DNS`服务解析

   - `Default`：`Pod`从宿主机上继承名称解析配置

5. `DNS`调试步骤：

   - 查看容器中的`resolv.conf`，验证是否正确设置了搜索路径和名称服务器。
   - 如果`resolv.conf`条目都是正确的，检查`kube-dns/coredns`插件是否启动，对应的`pod`是否运行
   - 检查后端`DNS Endpoint`是否准备好

二、`Kubernetes`网络策略

1. 总结

   - 默认情况下，`Kubernetes`底层网络是“全连通”的，即在同意集群内运行的所有`Pod`都可以自由通信。
   - 网络策略就是基于`Pod`源`IP`的访问控制列表，限制的是`Pod`之间的访问。
   - 通过定义网络策略，用户可以根据标签，`IP`范围和端口号的任意组合限制`Pod`的入站/出站流量
   - `Kubernetes`的网络策略采用了比较严格的单向流控制
   - `Kubernetes`网络是应用到每个节点上的，实现网络策略的`agent`需要以`DaemonSet`部署在每一个节点上，因此在实现上可能会有较大的性能影响

2. 网络策略应用举例

   1. 默认网络策略示例

      - 拒绝所有入站/出站流量

        ```yaml
        apiVersion: networking.k8s.io/v1
        kind: NetworkPolicy
        metadata:
          name: default-deny-all
        spec:
          podSelector: {}
          policyTypes:
          - Ingress
          - Egress
        ```

      - 允许所有入站流量

        ```yaml
        apiVersion: networking.k8s.io/v1
        kind: NetworkPolicy
        metadata:
          name: allow-all-ingress
        spec:
          podSelector: {}
          ingress:
          - {}
        ```

      - 允许所有出站流量

        ```
        apiVersion: networking.k8s.io/v1
        kind: NetworkPolicy
        metadata:
          name: allow-all-ingress
        spec:
          podSelector: {}
          egress:
          - {}
        ```

        注意：{}代表允许所有，[]表示拒绝所有

   2. `NetworkPolicy`核心字段

      - `apiVersion: networking.k8s.io/v1`
      - `kind: NetworkPolic`
      - `metadata`
      - `spec:`
        - `podSelector <Object> -required-`：用于指定网络策略在哪些`Pod`上生效，{}表示当前`namespace`下的所有`pod`，被匹配的`pod`默认拒绝所有出站入站流量，生效于定义的网络策略
          - `matchExpressions <[]Object>`
          - `matchLabels <map[string]string>`
        - `policyTypes <[]string>`：指定策略类型，包括`Ingress`和`Egress`，不指定默认就是`Ingress`
        - `ingress <[]Object>`：定义入站规则
          - `from <[]Object>`
          - `ports	<[]Object>`
        - `egress	<[]Object>`：定义出站规则
          - `to	<[]Object>`
          - `ports	<[]Object>`

   3. 定义示例：

      ```yaml
      apiVersion: networking.k8s.io/v1
      kind: NetworkPolicy
      metadata:
        name: test-network-policy
        namespace: default
      spec:
        podSelector:
          matchLabels:
            role: db
      # default名称空间下，Label包含role=db的pod，都会被隔绝所有流量      
        policyType:
        - Ingress
        - Egress
      # 它们只能满足Ingress和Egress描述的连接  
        ingress:
        - from: 
          - ipBlock:
              cidr: 172.17.0.0/16
              except:
              - 172.17.1.0/24
          - namespaceSelector:
              matchLabels:
                project: myproject
          - podSelector:
              matchLabels:
                role: frontend
        - ports:
          - protocol: TCP
            port: 6379
      # 所有属于172.17.0.0/16网段的IP，除了172.17.1.0/24，都可以与上述pod的6379端口建立建连接
      # 所有包含project=myproject Label的namespace中的Pod，都可以与上述pod的6379端口建立建连接
      # 所有default namespace下包含role=frontend Label的Pod都可以与上述pod的6379端口建立建连接
        egress:
        - to:
          - ipBlock:
              cidr: 10.0.0.0/24
        - ports:
          - protocol: TCP
            port: 5978
      # 允许上述Pod访问10.0.0.0/24网段的目的IP的5798端口      
      ```

三、`Kubernetes`网络故障定位

1. `IP`转发和桥接

   - 检查`IP`转发

     ```shell
     ## 检查ipv4 forwarding是否开启
     sysctl net.ipv4.ip_forward
     # 0表示未开启
     ## 开启IP转发功能
     sysctl -w net.ipv4.ip_forward=1
     echo net.ipv4.ip_forward=1 >> /etc/sysctl.conf
     sysctl -p
     ```

   - 检查桥接功能

     ```shell
     ## 检查是否开启bridge-netfilter
     sysctl net.bridge.bridge-nf-call-iptables
     ##开启bridge-netfilter
     modprobe br_netfilter
     sysctl -w net.bridge.bridge-nf-call-iptables=1
     echo net.bridge.bridge-nf-call-iptables=1 >> /etc/sysctl.conf
     sysctl -p
     ```

2. `Pod CIDR`冲突

   - 避免`Pod`网络和主机网络网段冲突

3. `hairpin`

   - 有时`Pod`无法通过`Service IP`访问自己，此时就需要检查`hairpin`配置
   - `kubelet`启动参数`--hairpin-mode`支持的值有`hairpin-veth`和`promiscuous-bridge`。
   - 如果`--hairpin-mode`被设置成`promiscuous-bridge`，需要把网桥配置成混杂模式

4. 查看`Pod IP`地址

   - `kubectl get pods -o wide`或者`kubectl describe pods POD_NAME`
   - 通过`downward API`
   - 进入到容器里面查看

5. 故障排查工具

   - `tcpdump`

     `tcpdump -i any host 172.28.21.3`

   - 容器镜像构建时内置网络工具

     ```shell
     # 自定义一个镜像用来调试网络，Dockerfile如下
     FROM library/python:3.3
     RUN apy-get update && apt-get -y install iproute2 net-tools ethtool nano
     CMD ["/usr/bin/python","-m","SimpleHTTPServer","5000"]
     ```

6. 为什么不推荐使用`SNAT`

   

