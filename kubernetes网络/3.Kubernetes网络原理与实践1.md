一、`Kubernetes`基本概念

1. 云原生：(`Cloud Native`)

   云原生技术有利于各组织在公有云，私有云和混合云等新型动态关井中，构建和运行可弹性扩展的应用。云原生的代表技术包括容器，服务网格，微服务，不可变基础设施和声明式`API`,这些技术能够构建容错性好，易于管理，便于观察的松耦合系统。结合可靠的自动化手段，云原生技术使工程师能够轻松的对系统做出频繁和可预测的重大改变

2. `Kubernetes`简介

   - `Pod`中的容器可以共享的资源有：
     - `PID`命名空间：`Pod`中的不同应用程序可以看到其他应用程序的进程`ID`(`k8s 1.8`之后取消了共享)
     - 网络命名空间：`Pod`中的多个容器能够访问同一个`IP`和端口范围
     - `IPC`命名空间：`Pod`中的多个容器能够使用`SystemV IPC`或`POSIX`消息队列进行通信
     - `UTS`命名空间：`Pod`中的多个容器共享一个主机名
     - `Volumes(共享存储卷)`：`Pod`中的各个容器可以访问在`Pod`级别定义的存储卷

3. `Kubernetes`实现的功能

   `Kubernetes`依赖其它项目提供完整的编排服务，要正确的实施`Kubernetes`可以集成云原生领域的其它开源项目，让用户可以管理自己的容器基础设施，例如

   - 仓库：`Harbor,Docker Registry`
   - 网络：`OpenvSwitch,CNI,Calico`
   - 监控：`Prometheus,Kibana,watchdog,Elastic`
   - 安全：`LDAP,SELinux,OAUTH,Spiffe`
   - 存储：`Rook,Torus`

二、`Kubernetes`网络

1. `k8s`网络模型需要解决的问题：

   - 各台服务器上的容器`IP`段不能重叠，所以需要某种`IP`段分配机制，为各台服务器分配独立的`IP`段
   - 从某个`Pod`发出的流量到达其所在服务器时，服务器的网络层应当具备根据目标`IP`地址，将流量转发到该`IP`所属`IP`段对应的目标服务器的能力
   - 总结起来，主要关注两方面：`IP`地址分配和路由

2. `k8s`网络基础

   1. `IP`地址分配
      - 节点网络
      - `pod`网络：用户可以在创建集群时通过`--pod-cidr`指定此范围
      - `ClusterIP`：集群网络，大部分情况下，集群网络不和节点网络在同一网段
   2. `Pod`出站流量
      - `Pod`到`Pod`：每个`Pod`都有自己的`IP`地址，运行在`Pod`内的应用都可以使用标准的端口号，不用重新映射到不同的随机端口号。所有的`Pod`之间都可以保持三层网络的连通性，比如可以`ping`通对方，相互发送数据包。
      - `Pod`到`Service`：为用户提供固定的访问端点，`Kubernetes`通过`Kube-proxy`实现这个功能，在每个节点都运行一个`Kube-proxy`进程，通过复杂的`iptables/IPVS`规则在`Pod`和`Service`之间进行各种过滤和`NAT`。
      - `Pod`到集群外：通过`SNAT`来处理。

3. `Kubernetes`架构综述

   1. 单`Pod`单`IP`模型
      - 每个`Pod`都有一个独立的`IP`，`pod`内所有容器共享一个`network namespace`。
      - 容器是一等公民，容器之间通信，不需要额外的`NAT`。
      - `Node`与容器网络直联，也不需要额外的`NAT`
   2. `k8s`创建一个`Pod`后，初始化网络协议栈的过程：
      - 当用户在`k8s`的`master`创建一个`pod`后，`kubelet`观察到新`pod`的创建，于是首先调用`CRI`创建`Pod`内的若干个容器
      - 创建第一个容器`pause`容器(具体逻辑是一启动就把自己阻塞在那里)，作用是占用一个`Linux`的`network namespace`。
      - `Pod`内的其它容器通过加入这个`network namespace`的方式共享同一个网络命名空间。
      - `Kubelet`目前支持两个网络驱动，分别是`Kubenet`和`CNI`，通过`CNI`实现容器的网络设备初始化工作，例如创建网络设备，例如`eth0`设备和分配`IP`地址。

4. `Kubernetes`主机内组网模型

   - `kubernetes`经典的主机内组网模型是`veth pair + bridge`方式
   - `kubernetes`使用`veth pair`将容器与主机的网络协议栈连接起来，容器放在主机根`network namespace`中`veth pair`的一端连接到`linux`网桥，可让同一节点上的各`Pod`之间相互通信。

5. `Kubernetes`跨节点组网模型

   `Kubernetes`跨接点组网解决方案主要有`bridge`和`overlay`两种：

   - 接在同一个网桥上的`Pod`通过局域网广播通信
   - `bridge`网络本身不解决容器的跨机通信问题，需要显式的书写主机路由表，映射目标容器网段和主机`IP`的关系，集群内如果有`N`个主机，需要`N-1`条路由表项
   - `overlay`网络，是构建在物理网络之上的一个虚拟网络，其中`VXLAN`是主流的`overlay`标准。`VXLAN`就是用`UDP`包头封装二层数据帧，即所谓的`MAC in UDP`

6. `Pod`的`hosts`文件

   在创建`pod`前，通过`pods.spec`字段的`hostAliases`字段为`pod`中的容器添加额外的`hosts`条目，通过`kubernetes`的`downward API`实现

   - `downward API`相关知识：`https://help.aliyun.com/document_detail/141788.html`

   示例：

   ```yaml
   apiVersion: v1
   kind: Pod
   metadata:
     name: hostaliases-pod
   spec:
     hostAliases:
     - ip: "127.0.0.1"
       hostnames:
       - "foo.local"
       - "bar.local"
     - ip: "10.1.1.3"
       hostnames:
       - "foo.remote"
       - "bar.remote"
     containers:
     - name: cat-hosts
       image: busybox
   ```

   注：如果`Pod`启用了`hostNetwork`（即使用主机网络），那么将不能使用`hostAliases`特性。

7. `Pod`的`hostname`

   1. 通过`UTS namespace`隔离技术实现`Pod`之间主机名相互隔离，但`Pod`内容器分享同一个主机名。
   2. 一个`Pod`内如果有多个容器，修改任意一个容器的`hostname`都会影响其它容器
   3. 如果通过`hostname`命令修改了主机名，容器重启或被`kubelet`重建都会使主机名恢复。

三、`Pod`的核心：`pause`容器

1. `Pause`容器的作用：
   - 在`Pod`中，它作为共享`Linux namespace`(`Network UTS`等)的基础
   - 启用`PID namespace`共享，它为每一个`Pod`提供1号进程，并收集`Pod`内的僵尸进程
2. 从`PID`看`pause`容器
   - 在`UNIX`系统中，`PID`为1的是`init`进程，即所有进程的父进程，`init`进程维护一张进程表并且不断地检查其它进程的状态。`init`进程的其中一个作用是当某个子进程由于父进程的错误退出而变成了孤儿进程，便会被`init`进程收养并在该进程退出时回收资源。
   - 在容器中，必须有一个进程充当每个`PID namespace`的`init`进程，使用`Docker`的话，`entrypoint`进程是`init`进程
3. 在`kubernetes`中使用`PID namespace`共享/隔离
   - 在`Kubernetes1.8+`，默认情况下禁用共享`PID namespace`，使用`--docer-disable-shared-pid=false`启用

四、`Kubernetes`网络驱动

1. `Kubernetes`支持的两种网络驱动

   - `CNI plugins`：遵守`appc/CNI`规范，允许自由接入多个符合`CNI`标准的网络插件
   - `kubenet plugins`：基于`cbr0`的一个单机容器网络方案，同时使用`CNI`的`bridge`和`host-local`实现一些功能

2. `kubenet`特色功能

   - 定制`MTU`

     `Kubenet`支持用户使用`Kubenet`的`--network-plugin-mtu`参数指定`MTU`

   - 带宽控制：

     支持通过`kubernetes.io/ingress-bandwidth`和`kubernetes.io/egress-bandwidth`这两个`annotations`设置`Pod`网络带宽限制，例如

     ```yaml
     apiVersion: v1
     kind: Pod
     metadata: 
       name: test
       annotations:
         kubernetes.io/ingress-bandwidth: 1M
         kubernetes.io/egress-bandwidth: 1M
     spec:
       containers:
       - name: test
         image: nginx:1.14-alpine
     ```

3. `CNI`基础

   1. 概述

      - `CNI`是容器网络的标准化，试图通过`JSON`描述一个容器网络配置
      - `CNI`是`Kubernetes`与底层网络插件之间的一个抽象层，为`Kubernetes`屏蔽了底层网络实现的复杂度，同时解耦了`kubernetes`的具体网络插件实现

   2. `CNI`接口

      - 创建容器时调用的配置网络接口

        ```go
        AddNetwork(net *NetworkConfig,rt* RuntimeConf)(types.Result,error)
        ```

      - 删除容器时调用的清理网络接口

        ```go
        DelNetwork(net *NetworkConfig,rt* RuntimeConf)
        
        // runtime配置主要是容器运行时传入的网络namespace信息
        ```

   3. 安装和使用`CNI`

      - 安装`CNI`

        `yum -y install kubernetes-cni`

      - 自定义网络

        ```shell
        cat > /etc/cni/net.d/10-mynet.conf <<EOF
        {
                "name": "mynet",
                "type": "bridge",
                "bridge": "cni0",
                "isGateway": true,
                "ipMasq": true,
                "ipam": {
                        "type": "local-host",
                        "subnet": "10.10.0.0/16",
                        "route": [
                                { "dst": "0.0.0.0/0" }
                        ]
                }
        }
        EOF
        ```

        - 在一个`Json`文件中，定义了名为`mynet`，它是一个`bridge`模型，`IP`地址管理`ipam`使用的是`host-local`(在本地用一个文件记录已经分配的容器`IP`地址)
        - `Kubenets`中的使用方法
          - `/etc/cni/net.d`用来存储`CNI`配置文件
          - `/opt/cni/bin`目录用来存放`CNI`插件的为进制文件

      - 在`Kubernetes`中使用`CNI`

        - `Kubelet`要使用`CNI`网络驱动需要配置启动参数`--network-plugin=cni`
        - 如果目录中有多个文件，则使用文件名字典序列中的第一个文件

      - `CNI`从`kubernetes1.11`开始支持`Pod`带宽控制，实现方式如下

        ```yaml
        apiVersion: v1
        kind: Pod
        metadata: 
          name: test
          annotations:
            kubernetes.io/ingress-bandwidth: 1M
            kubernetes.io/egress-bandwidth: 1M
        spec:
          containers:
          - name: test
            image: nginx:1.14-alpine
        ```

        - `Kubernetes`会自动为这个`Pod`分别限制上传和下载的带宽为`1Mb/s`，注意需要写`CNI`配置文件去调用`CNI`的默认`bandwidth`插件

          ```shell
          vim /etc/cni/net.d/my-net.conf
          {
          	"type": "bandwidth",
          	"capabilities": {"bandwidth": true}
          }
          ```

        - 用户通过`Pod`的`Annotations`下发带宽限制数值，`CNI`的`bandwidth`插件调用`Linux`流量控制插件`tc`，在宿主机上应用`tc`配置。

