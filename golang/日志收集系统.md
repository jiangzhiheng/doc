### 一、日志收集系统架构

1. 项目背景

   - 每个系统都有日志，当系统出现问题时，需要通过日志解决问题
   - 当系统机器比较少时，登录到服务器上查看即可满足
   - 当系统机器规模巨大，登录到服务器上就不太现实

2. 解决方案

   - 把机器上的日志实时收集，统一的存储到中心系统
   - 然后再对这些日志建立索引，通过搜索关键字即可找到对应日志
   - 通过提供友好的web界面，通过web即可完成日志搜索

3. 面临的问题

   - 实时日志量非常大
   - 日志准实时收集，延迟控制在分钟级别
   - 能够水平扩展

4. 业界方案ELK

   - 运维成本高，每增加一个日志收集，都需要手动修改配置
   - 监控缺失，无法准确获取`logstash`状态
   - 无法做定制化开发及维护

5. 日志收集系统设计

   `Log Agent------->Kafka()--------->ES------->Kibana`

   使用`kafka`: 数据解耦

6. 各组件介绍

   - `Log Agent`,日志收集客户端，用来收集服务器上的日志
   - `Kafka`，高吞吐量的分布式队列，`linkin`开发，apache顶级项目
   - `ES，elasticsearch`，开源的搜索引擎，提供`http restful`的web接口
   - `Hadoop`，分布式计算框架，能够对大量数据进行分布式处理的平台
   - `Storm`，实时分析框架

7. `kafka`应用场景

   - 异步处理，把关键流程异步化，提高系统的响应时间和健壮性
   - 应用解耦，通过消息队列
   - 流量削峰

8. `zookeeper`应用场景

   - 服务注册&服务发现
   - 配置中心
   - 分布式锁
     - `Zookeeper`是强一致的
     - 多个客户端同时在`Zookeeper`创建相同的`znode`，只有一个能创建成功

### 二、组件使用

1. kafka库使用

   ```go
   package main
   
   import (
   	"fmt"
   	"github.com/Shopify/sarama"
   )
   
   func main() {
   	//创建一个kafka配置
   	config := sarama.NewConfig()
   	config.Producer.RequiredAcks = sarama.WaitForAll  //消息持久化确认
   	config.Producer.Partitioner = sarama.NewRandomPartitioner   //随机partition
   	config.Producer.Return.Successes = true
   
   	client, err := sarama.NewSyncProducer([]string{"192.168.1.129:9092"}, config)
   	if err != nil {
   		fmt.Println("producer close, err:", err)
   		return
   	}
   
   	defer client.Close()
   
       msg := &sarama.ProducerMessage{}
   	msg.Topic = "nginx_log"
   	msg.Value = sarama.StringEncoder("this is a good test, my message is good")
   
   	pid, offset, err := client.SendMessage(msg)
   	if err != nil {
   		fmt.Println("send message failed,", err)
   		return
   	}
   
   	fmt.Printf("pid:%v offset:%v\n", pid, offset)
   }
   
   ```

2. tailf使用

   ```go
   package main
   
   import (
   	"fmt"
   	"github.com/hpcloud/tail"
   	"time"
   )
   func main() {
   	filename := "./my.log"
   	tails, err := tail.TailFile(filename, tail.Config{
   		ReOpen:    true,  //日志滚动时reopen  ，根据文件名追踪，并保持重试
   		Follow:    true,
   		Location:  &tail.SeekInfo{Offset: 0, Whence: 2}, //定义偏移量，断点续传，
   		MustExist: false, //日志文件一直存在，日志文件不存在也监控
   		Poll:      true,  //Poll for file changes instead of using inotify
   	})
   	if err != nil {
   		fmt.Println("tail file err:", err)
   		return
   	}
   	var msg *tail.Line
   	var ok bool
   	for true {
   		msg, ok = <-tails.Lines
   		if !ok {
   			fmt.Printf("tail file close reopen, filename:%s\n", tails.Filename)
   			time.Sleep(100 * time.Millisecond)
   			continue
   		}
   		fmt.Println("msg:", msg)
   	}
   }
   
   ```

3. 配置文件库使用

   - 初始化配置库
   - 读取配置项

   ```go
   package main
   
   import (
   	"fmt"
   	"github.com/astaxie/beego/config"
   )
   
   func main() {
   	conf, err := config.NewConfig("ini", "./logCollect.conf")
   	if err != nil {
   		fmt.Println("new config failed, err:", err)
   		return
   	}
   
   	port, err := conf.Int("server::port")
   	if err != nil {
   		fmt.Println("read server:port failed, err:", err)
   		return
   	}
   
   	fmt.Println("Port:", port)
   	log_level, err := conf.Int("log::log_level")
   	if err != nil {
   		fmt.Println("read log_level failed, ", err)
   		return
   	}
   	fmt.Println("log_level:", log_level)
   
   	log_path := conf.String("log::log_path")
   	fmt.Println("log_path:", log_path)
   
   }
   ```

4. 日志库的使用

   - 配置log组件
   - 初始化日志组件

   ```go
   package main
   
   import (
   	"encoding/json"
   	"fmt"
   	"github.com/astaxie/beego/logs"
   )
   
   func main() {
   	config := make(map[string]interface{})
   	config["filename"] = "./logs/logcollect.log"
   	config["level"] = logs.LevelDebug
   
   	configStr, err := json.Marshal(config)
   	if err != nil {
   		fmt.Println("marshal failed, err:", err)
   		return
   	}
   
   	logs.SetLogger(logs.AdapterFile, string(configStr))
   
   	logs.Debug("this is a test, my name is %s", "stu01")
   	logs.Trace("this is a trace, my name is %s", "stu02")
   	logs.Warn("this is a warn, my name is %s", "stu03")
   }
   ```