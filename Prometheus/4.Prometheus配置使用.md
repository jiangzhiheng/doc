一、`Prometheus`监控`Kubernetes`之服务配置

1. 静态配置

   1. 概述：

      - 如果服务自己提供了`/metrics`数据接口，直接配置即可
      - 如果服务本身没有提供`metrics`数据接口，就需要借助`exporter`服务来实现，对于这类应用，在一般情况下会以一个`SideCar`容器的形式将其与主应用部署在同一个`Pod`中。

   2. `Redis`服务部署示例

      1. 创建`prome-redis.yaml`

         ```yaml
         apiVersion: apps/v1
         kind: Deployment
         metadata:
           name: redis
           namespace: kube-ops
         spec:
           replicas: 1
           selector:
             matchLabels:
               app: redis
           template:
             metadata:
               annotations:
                 prometheus.io/scrape: "true"
                 prometheus.io/scrape: "9121"
               labels:
                 app: redis
             spec:
               containers:
               - name: redis
                 image: redis:4
                 resources:
                   requests:
                     cpu: 100m
                     memory: 100Mi
                 ports:
                 - containerPort: 6379
               - name: redis-exporter
                 image: oliver006/redis_exporter:latest
                 resources:
                   requests:
                     cpu: 100m
                     memory: 100Mi
                 ports:
                 - containerPort: 9121
         ---
         apiVersion: v1
         kind: Service
         metadata:
           name: redis
           namespace: kube-ops
         spec:
           selector:
             app: redis
           ports:
           - name: redis
             port: 6379
             targetPort: 6379
           - name: prom
             port: 9121
             targetPort: 9121
         ```

      2. 验证配置的服务及指标获取验证

         ```shell
         [root@master redisdemo]# kubectl get po -n kube-ops 
         NAME                          READY   STATUS    RESTARTS   AGE
         prometheus-5cd7b955f4-n9j9s   1/1     Running   0          13m
         redis-68ccfdfc87-fffqm        2/2     Running   0          116s
         [root@master redisdemo]# kubectl get svc -n kube-ops
         NAME         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE
         prometheus   NodePort    10.107.138.232   <none>        9090:30967/TCP      13m
         redis        ClusterIP   10.96.10.35      <none>        6379/TCP,9121/TCP   2m7s
         [root@master redisdemo]# curl 10.96.10.35:9121/metrics
         .....
         # HELP redis_aof_last_cow_size_bytes aof_last_cow_size_bytes metric
         # TYPE redis_aof_last_cow_size_bytes gauge
         redis_aof_last_cow_size_bytes 0
         # HELP redis_aof_last_rewrite_duration_sec aof_last_rewrite_duration_sec metric
         # TYPE redis_aof_last_rewrite_duration_sec gauge
         redis_aof_last_rewrite_duration_sec -1
         # HELP redis_aof_last_write_status aof_last_write_status metric
         # TYPE redis_aof_last_write_status gauge
         redis_aof_last_write_status 1
         # HELP redis_aof_rewrite_in_progress aof_rewrite_in_progress metric
         # TYPE redis_aof_rewrite_in_progress gauge
         redis_aof_rewrite_in_progress 0
         # HELP redis_aof_rewrite_scheduled aof_rewrite_scheduled metric
         # TYPE redis_aof_rewrite_scheduled gauge
         redis_aof_rewrite_scheduled 0
         ......
         ```

      3. 配置`Prometheus`的配置文件

         ```yaml
         # vim prometheus-cm.yaml
         kind: ConfigMap
         apiVersion: v1
         metadata:
           labels:
             app: prometheus
           name: prometheus-config
           namespace: kube-ops
         data:
           prometheus.yml: |
             global:
               scrape_interval: 15s
               scrape_timeout: 15s
             scrape_configs:
             - job_name: 'prometheus'
               static_configs:
               - targets: ['localhost:9090']
             - job_name: 'redis'
               static_configs:
               - targets: ['redis:9121']   
           # 直接使用服务名访问
           kubectl apply -f  prometheus-cm.yaml
           # 重载prometheus配置
           curl -X POST "http://10.107.138.232:9090/-/reload"
         ```

      4. 前往`Prometheus`的`Dashboard`验证

2. 服务发现配置

   1. 概述

      - 在`Kubernetes`下，`Prometheus`通过与`Kubernetes API`集成来完成自动发现，目前主要支持5中服务发现模式：`Node,Service,Pod,Endpoints,Ingress`

   2. 示例：如果要让`Prometheus`能够获取当前集群中的所有节点信息，就需要利用`Node`的服务发现模式，在`prometheus.yml`文件中配置如下`Job`

      - 修改`Prometheus`配置文件

        ```yaml
        kind: ConfigMap
        apiVersion: v1
        metadata:
          labels:
            app: prometheus
          name: prometheus-config
          namespace: kube-ops
        data:
          prometheus.yml: |
            global:
              scrape_interval: 15s
              scrape_timeout: 15s
            scrape_configs:
            - job_name: 'prometheus'
              static_configs:
              - targets: ['localhost:9090']
            - job_name: 'redis'
              static_configs:
              - targets: ['redis:9121']
        # Prometheus在发现Node模式Service时，访问的默认端口10250，而目前kubelet在该端口已经没有指标数据了，如果需要获取主机的监控信息，就需要借助node-exporter，它的暴露端口是9090，而上面的prometheus的请求端口是10250，需要用到prometheus提供的relabel_configs中的replace功能      
            - job_name: 'kubernetes-nodes'
              kubernetes_sd_configs:
              - role: node
              relabel_configs:
              - source_labels: [__address__]
                regex: '(.*):10250'
                replacement: '${1}:9100'
                target_label: __address__
                action: replace
        # 更新配置文件，重载prometheus配置
        kubectl apply -f prometheus-cm.yaml
        curl -X POST "http://10.107.138.232:9090/-/reload"
        ```

      - 通过`labelmap`动作重新定义`kubernetes`的标签，例如

        ```yaml
            - job_name: 'kubernetes-nodes'
              kubernetes_sd_configs:
              - role: node
              relabel_configs:
              - source_labels: [__address__]
                regex: '(.*):10250'
                replacement: '${1}:9100'
                target_label: __address__
                action: replace
              - action: labelmap
                regex: __meta_kubernetes_node_label_(.+)
        # 以上配置添加了一个action为labelmap且正则表达式是 __meta_kubernetes_node_label_(.+)的配置，意思是将表达式中匹配的数据也添加到指标数据的标签中       
        ```

        - `kubernetes_sd_config`可用的`Meta`信息标签如下：
          - `__meta_kubernetes_node_name`：节点对象的名称
          - `__meta_kubernetes_node_label`：节点对象的每个标签
          - `__meta_kubernetes_node_annotation`：来及节点对象的每个注释
          - `__metadata_kubernetes_node_address`：每个节点地址类型的第一个地址

      - `Kubelet`也自带了一些监控指标数据，并且通过10255端口对外暴露：配置如下

        ```yaml
            - job_name: 'kubernetes-kubelet'
              kubernetes_sd_configs:
              - role: node
              relabel_configs:
              - source_labels: [__address__]
                regex: '(.*):10250'
                replacement: '${1}:10255'
                target_label: __address__
                action: replace
              - action: labelmap
                regex: __meta_kubernetes_node_label
        ```

二、`Prometheus`监控`Prometheus`之监控对象

1. 容器监控

   1. `Prometheus`的配置方式

      - 容器监控通过`kubelet`组件内置的`cAdvisor`组件，数据路径为`/api/v1/node/节点名称/proxy/metrics`

      - `Prometheus`中配置如下

        ```yaml
            - job_name: kubernetes-cadvisor
              scrape_interval: 1m
              scrape_timeout: 10s
              metrics_path: /metrics
              scheme: https
              kubernetes_sd_configs:
              - api_server: null
                role: node
                namespaces:
                  names: []
              bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
              tls_config:
                ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
                insecure_skip_verify: false
              relabel_configs:
              - separator: ;
                regex: __meta_kubernetes_node_label_(.+)
                replacement: $1
                action: labelmap
              - separator: ;
                regex: (.*)
                target_label: __address__
                replacement: kubernetes.default.svc:443
                action: replace
              - source_labels: [__meta_kubernetes_node_name]
                separator: ;
                regex: (.+)
                target_label: __metrics_path__
                replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor
                action: replace
        ```

   2. 容器指标

      1. `CPU`

         - 常用指标

           - `container_cpu_user_seconds_total`：容器用户态占用`CPU`的时间总和
           - `container_cpu_system_seconds_total`：容器内核态占用`CPU`的时间总和
           - `container_cpu_usage_seconds_total`：容器占用`CPU`的总和

         - 示例：由于这些指标都是计数器类型的，所以可以通过`rate`函数获取样本变化率

           ```sql
           sum(
           rate(container_cpu_usage_seconds_total[5m]))
           by (container_name)
           ```

      2. 内存

         - 常用指标

           - `container_memory_cache`：内存中的`cache`用量
           - `container_memory_rss`：常驻的内存用量
           - `container_memory_swap`：交换分区用量
           - `container_memory_usage_bytes`：内存的总占用量

         - 示例：

           ```
           container_memory_usage_bytes{
           pod_name="kube-flannel-ds-amd64-qhrcg"
           }
           ```

      3. 磁盘`IO`

         - 常用指标

           - `container_fs_writes_bytes_total`：磁盘写总量
           - `container_fs_reads_bytes_total`：磁盘读总量

         - 示例：计数器指标，查看瞬时读写需要`rate`函数

           ```
           sum(
           rate(container_fs_writes_bytes_total[5m]))
           by (container_name,device)
           ```

      4. 网络`IO`

         - 常用指标
           - `container_network_receive_bytes_total`：即接收的总字节数
           - `container_network_transmit_bytes_total`：磁盘发送的总字节数
         - 针对网络异常情况的监控：
           - `container_network_receive_packets_dropped_total`：网络接收丢包数
           - `container_network_transmit_packets_droped_total`：网络发送丢包数
           - `container_network_receive_errors_tatal`：网络接收错误总数
           - `container_network_transmit_errors_total`：网络发送错误总数

2. `apiserver`监控

   1. `Prometheus`配置

      ```yaml
          - job_name: kubernetes-apiservers
            scrape_interval: 1m
            scrape_timeout: 10s
            metrics_path: /metrics
            scheme: https
            kubernetes_sd_configs:
            - api_server: null
              role: endpoints
              namespaces:
                names: []
            bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
            tls_config:
              ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
              insecure_skip_verify: true
            relabel_configs:
            - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
              separator: ;
              regex: default;kubernetes;https
              replacement: $1
              action: keep
      # keep 符合要求的保留下来       
      ```

      - 注意：如果要配置`kube-scheduler`或`kube-controller-manager`，则需要提前手动创建这两个服务的`Service`，其中`kube-scheduler`的指标数据的端口为10251，`kube-controller-manager`的指标数据的端口为10252

   2. `apiserver`指标

      - `kube-apiserver`组件提供整个`kubernetes`的接入服务，需要关注的指标主要是接口被请求的次数及延迟，可通过`apiserver_request_count`请求总数获取接口请求次数，`PromQL`表达式如下：

        ```
        sum(
        rate(apiserver_request_total[5m])
        ) by (resource,subresource,verb)
        ```

      - 如果需要获取`kube-apiserver`性能，则可以通过`kube-apiserver`接口获取延迟时间，`PromQL`表达式如下

        ```
        histogram_quantile(0.9,
        sum(rate(apiserver_request_latecies_bucket[5m]))
        by (le,resource,subresource,verb) ) / 1e+6
        ```

3. `Service`监控

   1. 定义`Prometheus`的配置文件来发现普通类型的`Service`

      ```yaml
          - job_name: kubernetes-service-endpoints
            kubernetes_sd_configs:
            - role: endpoints
            relabel_configs:
            - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
              regex: true
              action: keep
            - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
              regex: (https?)
              target_label: __scheme__
              action: replace
            - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
              regex: (.+)
              target_label: __metrics_path__
              action: replace
            - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
              regex: ([^:]+)(?::\d+)?;(\d+)
              target_label: __address__
              replacement: $1:$2
              action: replace
            - separator: ;
              regex: __meta_kubernetes_service_label_(.+)
              replacement: $1
              action: labelmap
            - source_labels: [__meta_kubernetes_namespace]
              separator: ;
              regex: (.*)
              target_label: kubernetes_namespace
              replacement: $1
              action: replace
            - source_labels: [__meta_kubernetes_service_name]
              separator: ;
              regex: (.*)
              target_label: kubernetes_name
              replacement: $1
              action: replace
      # 将__meta_kubernetes_service_annotation_prometheus_io_scrape为true的指标保留下来，如果需要自动发现集群中的service，添加对应annotation即可        
      ```

   2. 在配置`Service`时添加以下`Annotations`即可

      ```yaml
      apiVersion: v1
      kind: Service
      metadata:
        name: redis
        namespace: kube-ops
        annotations:
          prometheus.io/scrape: "true"   # 定义自动发现
          prometheus.io/port: "9121"     # 指定指标数据的端口
      spec:
        selector:
          app: redis
        ports:
        - name: redis
          port: 6379
          targetPort: 6379
        - name: prom
          port: 9121
          targetPort: 912
      ```

4. `kube-state-metrics`监控

   1. 概述：

      - 在`Kubernetes`集群上也需要监控`Pod,DaemonSet,Deployment,Job,Crontab`等资源对象的状态，这可以反映出使用这些资源部署的应用的状态。

      - `Kubernetes`提供的`kube-state-metrics`项目提供了这些功能

        `https://github.com/kubernetes/kube-state-metrics.git`

   2. 部署该功能

      - `https://gitee.com/jzh_k/kube-state-metrics.git`

      - `cd kube-state-metrics/examples/standard/`修改为适合自己需要的形式

        `https://github.com/jiangzhiheng/k8sDemo/tree/master/prometheus/simple_install/kube-state-metrics`

5. 主机监控

   1. 部署`node-exporter`

      ```yaml
      apiVersion: apps/v1
      kind: DaemonSet
      metadata:
        name: node-exporter
        namespace: kube-ops
        labels:
          k8s-app: node-exporter
          kubernetes.io/cluster-service: "true"
          addonmanager.kubernetes.io/mode: Reconcile
      spec:
        updateStrategy:
          type: OnDelete
        selector:
          matchLabels:
            k8s-app: node-exporter
            version: v0.17.0
        template:
          metadata:
            labels:
              k8s-app: node-exporter
              version: v0.17.0
          spec:
            containers:
            - image: prom/node-exporter:v0.17.0
              name: prometheus-node-exporter
              imagePullPolicy: IfNotPresent
              args:
              - --path.procfs=/host/proc
              - --path.sysfs=/host/sys
              - --collector.filesystem.ignored-mount-points
              - '"^/(sys|proc|dev|host|etc)($|/)"'
              ports:
              - containerPort: 9100
                hostPort: 9100
                name: metrics
              volumeMounts:
              - name: proc
                mountPath: /host/proc
                readOnly: true
              - name: sys
                mountPath: /host/sys
                readOnly: true
              - name: dev
                mountPath: /host/dev
              - name: rootfs
                mountPath: /rootfs
              resources:
                limits:
                  cpu: 1
                  memory: 512Mi
                requests:
                  cpu: 100m
                  memory: 50Mi
            hostNetwork: true
            hostPID: true
            tolerations:
            - key: node-role.kubernetes.io/master
              operator: "Exists"
              effect: "NoSchedule"
            volumes:
            - name: proc
              hostPath:
                path: /proc
            - name: sys
              hostPath:
                path: /sys
            - name: dev
              hostPath:
                path: /dev
            - name: rootfs
              hostPath:
                path: /
      ---
      apiVersion: v1
      kind: Service
      metadata:
        labels:
          k8s-app: node-exporter
          kubernetes.io/cluster-service: "true"
          addonmanager.kubernetes.io/mode: Reconcile
        name: node-exporter
        namespace: kube-ops
        annotations:
          prometheus.io/scrape: "true"
      spec:
        clusterIP: None
        ports:
        - name: metrics
          port: 9100
          protocol: TCP
          targetPort: 9100
        selector:
          k8s-app: node-exporter
      # 由于已经指定了hostNetwork=true，所以在每一个节点上都会监控一个9100端口，也可以不定义service            
      ```