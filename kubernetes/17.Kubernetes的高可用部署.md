一、手动部署的高可用方案

1. `etcd`的高可用部署

   1. 配置要点：

      - `etcd`需要以集群的方式进行部署，以实现`etcd`数据存储的冗余，备份和高可用
      - `etcd`存储的数据本身也应考虑使用可靠的存储设备。

   2. 规划要点：

      - `etcd`集群的部署可以使用静态配置，也可使用`etcd`提供的基于`REST API`在运行时动态添加、修改或删除集群中的成员
      - 节点数量推荐至少为3个

   3. 配置文件示例：

      `/etc/etcd/etcd.conf`

      ```shell
      # [member]
      ETCD_NAME=etcd1   # ETCD实例的名称
      ETCD_DATA_DIR="/var/lib/etcd"   # ETCD数据保存目录
      ETCD_LISTEN_CLIENT_URLS="http://10.0.0.1:2379,http://127.0.0.1:2379"  # 供外部客户端使用的URL
      ETCD_ADVERTISE_CLIENT_URLS="http://10.0.0.1:2379,http://127.0.0.1:2379" #s 广播给外部客户端使用的URL
      # [cluster]
      ETCD_LISTEN_PEER_URLS="http://10.0.0.1:2380"  # 集群内部通信使用的URL
      ETCD_INITIAL_ADVERTISE_PEER_URLS="http://10.0.0.1:2380"  # 广播给集群内其它成员访问的URL
      ETCD_INITIAL_CLUSTER="etcd1=http://10.0.0.1:2380,etcd2=http://10.0.0.2:2380,etcd3=http://10.0.0.3:2380"  # 初始集群成员列表
      ETCD_INITIAL_CLUSTER_STATE="new"  # 初始集群状态，new为新建集群
      ETCD_INITIAL_CLUSTER_TOKEN="etcd-cluster" #集群名称
      ```

      - 其它两个节点配置文件相同，只需修改对应节点地址即可

   4. 启功三个节点上的`etcd`服务

      `systemctl restart etcd`

   5. 验证集群状态：

      `etcdctl cluster-health`

      `etcdctl member list`

   6. 参考文档：`https://etcd.io/docs/v3.4.0/op-guide/clustering/`

2. `Master`的高可用部署

   1. 配置要点：
      - `Kubernetes`建议`Master`的3个组件都已容器的形式启动，启动它们的基础工具是`kubelet`，所以他们都将以`Static Pod`的形式启动并将由`kubelet`监控和自动重启。
      - `kubelet`本身的高可用则通过操作系统来完成，例如使用`Linux`的`Systemd`系统进行管理
   2. `kube-apiserver`的高可用部署
      1. 假设`kubelet`的启动参数指定`--config=/etc/kubernetes/manifests`，即`Static Pod`定义文件所在的目录，接下来就可以创建`kube-apiserver.yaml`配置文件用于启动`kube-apiserver`了
      2. `YAML`文件示例：权威指南705页
      3. 配置要点：
         - `kube-apiserver`需要使用`hostNetwork`模式，即直接使用宿主机网络，可以使客户端能够通过物理机访问其`API`
         - 端口号的设置都配置了`hostPort`，将容器内的端口号直接映射为宿主机的端口号
         - 为三个节点执行重复的操作，使得在每台服务器上都启动一个`kube-apiserver`的`Pod`
      4. 为`kube-apiserver`配置负载均衡器
         - 在不同的平台下，负载均衡的实现方式不同：
           - 在一些公有云如`GCE、AWS`、阿里云上都有现成的实现方案
           - 对于本地集群，我们可以选择硬件或者软件来实现负载均衡，`Kubernetes`社区推荐的方案`HAProxy`和`Keepalived`，其中`HAProxy`负责负载均衡，`Keepalived`负责对`HAProxy`进行监控和故障切换
         - 配置要点：
           - 如果`Master`开启了安全认证机制，那么需要确保在`CA`证书中包含负载均衡服务节点的`IP`
           - 对于外部的访问，比如通过`kubectl`访问`API Server`，需要配置为访问`API Server`对应的负载均衡器的`IP`地址
   3. `kube-controller-manager`和`kube-scheduler`的高可用配置
      1. 概述
         - 不同于`API Server`，`Master`另外两个组件`kube-controller-manager`和`kube-scheduler`会修改集群的状态信息
         - 因此，对于`kube-controller-manager`和`kube-scheduler`而言，高可用不仅意味着需要启动多个实例，还需要这些个实例能实现选举并选举出`leader`，以保证同一时间只有一个实例可以对集群状态信息进行读写，避免痴线同步问题和一致性问题
         - `Kubernetes`对于这种选举机制的实现是通过租赁锁（`lease-lock`）来实现的，我们可以通过在这两个组件的启动参数中设置`--leader-elect=true`，来保证同一时间只会运行一个可修改集群信息的实例。
      2. 具体实现步骤
         - 在每个`Master`上都创建对应的日志文件
         - 创建`kube-controller-manager`和`kube-scheduler`的`YAML`配置文件
         - 将这两个文件复制到`kubelet`监控的`/etc/kubernetes/manifests`目录下。

二、使用`kubeadm`的高可用部署方案