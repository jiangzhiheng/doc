一、`k8s`资源调度及调度策略

1. `k8s`中资源调度顺序

   `Predicate`预选 --->  `Priority`(优选) ---> `Select`(选定)

2. 常用预选策略

   - `CheckNodeCondition:`
   - `GeneralPredicates:`
     - `HosName`：检查`Pod`对象是否定义了`pod.spec.hostname`
     - `PodFitsHostPorts`：`pods.spec.containers.ports.hostPort`
     - `MatchNodeSelector`：`pods.spec.nodeSelector`
     - `PodFitsRescources`：检查`Pod`的资源需求是否能被节点所满足
   - `NoDiskConflict`：检查`Pod`依赖的存储卷是否能满足需求
   - `PodToleratesNodeTaints`：检查`Pod`上的`spec.tolerations`可容忍的污点是否完全包含节点上的污点
   - `PodToleratesNodeNoExecuteTaints：`
   - `CheckNodeLabelPresence：`
   - `CheckServiceAffinity：`
   - `CheckVolumeBinding：`
   - `NoVolumeZoneConflict：`
   - `CheckNodeMemoryPressure`
   - `CheckNodePIDPressure`
   - `CheckNodeDiskPressure`
   - `MatchInterPodAffinity`

3. 优选函数

   - `LeastRequested：`：节点上资源的占用比率

     `（cpu((capacity-sum(requested))*10/capacity)+memory((capacity-sum(requested))*10/capacity))/2`

   - `BalancedResourceAllocation:`

     `CPU`和内存资源占用率相近的胜出

   - `NodePreferAvoidPods：`

     节点注解信息`"scheduler.alpha.kubernetes.io/preferAvoidPods"`

   - `TaintToleration：`将Pod对象的`spec.tolerations`列表项与节点的`taints`列表项进行匹配度检查，匹配条目越多，得分越低

   - `SelectorSpreading`

   - `InterPodAffinity`

   - `NodeAffinity`

   - `MostRequested`

   - `NodeLabel`

   - `ImageLocality`

二、高级资源调度

1. 节点选择器：`nodeSelector,nodeName`

   - 核心字段

     `kubectl explain pods.spec.nodeSelector`

     - `nodeSelector <map[string]string>`：选择有指定标签的节点进行调度

   - 配置示例

     ```yaml
     apiVersion: v1
     kind: Pod
     metadata:
       name: pod-demo01
       namespace: default
       labels:
         app: myapp
         tier: frontend
     spec:
       containers:
       - name: myapp
         image: nginx:1.13-alpine
       nodeSelector:
         disktype: ssd  # 选择调度到节点标签为disktype=ssh的节点
     # kubectl label nodes node01 disktype=ssd 
     ```

2. 节点亲和性调度

   - 核心字段

     `kubectl explain pods.spec.affinity.nodeAffinity`

     - `nodeAffinity <Object>`
       - `preferredDuringSchedulingIgnoredDuringExecution <[]Object>`
         - `preference	<Object> -required-`
           - `matchExpressions	<[]Object>`
             - `key <string> -required-`
             - `operator <string> -required-`
             - `values	<[]string>`
           - `matchFields <[]Object>`
             - `key <string> -required-`
             - `operator <string> -required-`
             - `values	<[]string>`
         - `weight	<integer> -required-`
       - `requiredDuringSchedulingIgnoredDuringExecution	<Object>`
         - `nodeSelectorTerms	<[]Object> -required-`
           - `matchExpressions <[]Object>`
           - `matchFields <[]Object>`

   - 配置示例1：硬亲和性调度

     ```yaml
     apiVersion: v1
     kind: Pod
     metadata:
       name: pod-affinity01-demo
       namespace: default
       labels:
         app: myapp
         tier: frontend
     spec:
       containers:
       - name: myapp
         image: nginx:1.13-alpine
       affinity:
         nodeAffinity:
           requiredDuringSchedulingIgnoredDuringExecution:
             nodeSelectorTerms:
             - matchExpressions:
               - key: zone
                 operator: In
                 values:
                 - foo
                 - bar
     # 对于硬亲和性调度，如果条件不匹配，pod将会pending            
     ```

   - 配置实例2：软亲和性调度

     ```yaml
     apiVersion: v1
     kind: Pod
     metadata:
       name: pod-affinity01-demo
       namespace: default
       labels:
         app: myapp
         tier: frontend
     spec:
       containers:
       - name: myapp
         image: nginx:1.13-alpine
       affinity:
         nodeAffinity:
           preferredDuringSchedulingIgnoredDuringExecution:
           - preference:
               matchExpressions:
               - key: zone
                 operator: In
                 values:
                 - foo
                 - bar
             weight: 60
     ```

3. `Pod`亲和性调度

   - 核心字段

     `kubectl explain pods.spec.affinity.podAffinity`

     - `podAffinity <Object>`
       - `preferredDuringSchedulingIgnoredDuringExecution <[]Object>`：软亲和性调度
         - `podAffinityTerm <Object> -required-`
           - `labelSelector <Object>`：选择要亲和性的`pod`标签
             - `matchExpressions <[]Object>`
             - `matchLabels <map[string]string>`
           - `namespaces	<[]string>`
           - `topologyKey <string> -required-`：定义要运行的节点组的`key`值
         - `weight	<integer> -required-`
       - `requiredDuringSchedulingIgnoredDuringExecution	<[]Object>`：硬亲和性调度
         - `labelSelector	<Object>`
         - `namespaces	<[]string>`
         - `topologyKey	<string> -required-`

   - 配置示例1：硬亲和性调度

     ```yaml
     apiVersion: v1
     kind: Pod
     metadata:
       name: pod-first
       labels:
         app: myapp
         tier: frontend
     spec:
       containers:
       - name: myapp
         image: nginx:1.13-alpine
     ---
     apiVersion: v1
     kind: Pod
     metadata:
       name: pod-second
       labels:
         app: backend
         tier: db
     spec:
       containers:
       - name: busybox
         image: busybox:latest
         imagePullPolicy: IfNotPresent
         command: ["sh","-c","sleep 3600"]
       affinity:
         podAffinity:
           requiredDuringSchedulingIgnoredDuringExecution:
           - labelSelector:
               matchExpressions:
               - { key: app, operator: In, values: ["myapp"] }  # 匹配有app=myapp标签的pod资源，并与之运行在具有同一topologyKey拓扑域的节点上
             topologyKey: kubernetes.io/hostname
     ```

   - 配置示例2：反亲和性调度

     ```yaml
     apiVersion: v1
     kind: Pod
     metadata:
       name: pod-first
       labels:
         app: myapp
         tier: frontend
     spec:
       containers:
       - name: myapp
         image: nginx:1.13-alpine
     ---
     apiVersion: v1
     kind: Pod
     metadata:
       name: pod-second
       labels:
         app: backend
         tier: db
     spec:
       containers:
       - name: busybox
         image: busybox:latest
         imagePullPolicy: IfNotPresent
         command: ["sh","-c","sleep 3600"]
       affinity:
         podAntiAffinity:
           requiredDuringSchedulingIgnoredDuringExecution:
           - labelSelector:
               matchExpressions:
               - { key: app, operator: In, values: ["myapp"] }
             topologyKey: kubernetes.io/hostname
     # 匹配app=myapp的pod资源，并与之必须不能运行于同一节点上，并且topologyKey也不能被匹配，也就是说，如果第一个pod运行在具有指定topologyKey的节点上的话，另一个pod一定不能被调度到具有topologyKey的节点上，第二个pod会被pending        
     ```

4. 污点调度

   1. 污点定义：

      - 定义方式

        `kubectl taint NODE NAME KEY_1=VAL_1:TAINT_EFFECT_1`

      - `taint`的`effect`定义对`pod`的排斥效果

        - `NoSchedule`：仅影响调度过程，对现存的Pod对象不产生影响；
        - `NoExecute`：既影响调度过程，也影响现在的Pod对象，不能容忍污点的现存Pod将被驱逐
        - `PreferNoSchedule`

   2. 配置示例

      - `taint`定义示例
        - `kubectl taint node node1 node-type=production:NoSchedule`
        - `kubectl taint node node1 node-type=dev:NoExecute`

   3. 容忍度定义

      - 核心字段

        `kubectl explain pods.spec.tolerations`

        - `tolerations <[]Object>`
          - `effect	<string>`
          - `key <string>`
          - `operator <string>`
          - `tolerationSeconds	<integer>`
          - `value	<string>`

      - 配置示例

        ```yaml
        apiVersion: apps/v1
        kind: Deployment
        metadata:
          name: myapp-deploy
          namespace: default
        spec:
          replicas: 5
          selector:
            matchLabels:
              app: myapp
              release: canary
          template:
            metadata:
              name: myapp-demo
              labels:
                app: myapp
                release: canary
            spec:
              containers:
              - name: myapp
                image: nginx:1.13-alpine
                ports:
                - name: http
                  containerPort: 80
              tolerations:
              - key: "node-type"
                operator: "Equal"
                value: "production"
                effect: "Noschedule"
                tolerationSeconds: 60
        ```

5. 补充

   1. 关于`nodeAffinity`调度

      - 如果同时定义了`nodeSelector`和`nodeAffinity`，那么必须两个条件都得到满足`Pod`才能最终运行到指定的`node`上
      - 如果`nodeAffinity`指定了多个`nodeSelectorTerms`，那么其中一个能够匹配成功即可
      - 如果在`nodeSelectorTerms`有多个`matchExpressions`，则一个节点必须满足所有`matchExpressions`才能运行该`Pod`

   2. 关于`taint`和`toleration`的应用

      - 独占节点
      - 具有特殊硬件设备的节点
      - 定义`Pod`驱逐行为，以应对节点故障

   3. `Pod`优先级调度：`Pod Priority Preemption`     

      -  `Eviction`：驱逐

      - `Preemption`：抢占

      - 示例：

        - 创建`Priority Class`

          ```yaml
          apiVersion: scheduling.k8s.io/v1
          kind: PriorityClass
          metadata:
            name: high-priority
          value: 1000000
          globalDefault: false
          description: "This priority class should be used for XYZ service pod only."
          ```

        - 引用创建的优先级类别

          ```yaml
          apiVersion: v1
          kind: Pod
          metadata:
            name: nginx
            labels:
              env: test
          spec:
            containers:
            - name: myapp
              image: nginx:1.14-alpine
            priorityClassName: high-priority
          ```

      